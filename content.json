{"meta":{"title":"moonkie","subtitle":"Living like a beam of light","description":null,"author":"moonkie","url":"https://moonkie.xyz"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-10-02T09:46:39.977Z","updated":"2018-10-02T09:46:39.977Z","comments":false,"path":"/404.html","permalink":"https://moonkie.xyz//404.html","excerpt":"","text":""},{"title":"关于我","date":"2018-10-02T08:42:20.000Z","updated":"2018-10-02T16:47:19.952Z","comments":true,"path":"about/index.html","permalink":"https://moonkie.xyz/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-10-02T13:36:43.212Z","updated":"2018-10-02T13:36:43.212Z","comments":false,"path":"categories/index.html","permalink":"https://moonkie.xyz/categories/index.html","excerpt":"","text":""},{"title":"分类 & 标签","date":"2018-10-02T16:47:37.642Z","updated":"2018-10-02T16:47:37.642Z","comments":false,"path":"tags/index.html","permalink":"https://moonkie.xyz/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"并行计算性能测评","slug":"并行计算性能测评","date":"2018-04-08T12:23:09.000Z","updated":"2018-10-02T11:50:57.655Z","comments":true,"path":"2018/04/08/并行计算性能测评/","link":"","permalink":"https://moonkie.xyz/2018/04/08/并行计算性能测评/","excerpt":"&emsp;&emsp; 并行计算的性能评测，大致分为三个层级：机器级、算法级、程序级。机器级的性能评测主要包括 CPU 和存储器的某些基本性能指标，并行通信开销，性价比等；算法级性能评测主要包括加速、效率、可扩放性等；程序级性能评测主要包括在基本测试程序、数学库测试程序和并行测试程序等。 —— 摘自 陈国良《并行计算 算法·结构·编程》 &emsp;&emsp; 本文主要集中讨论算法级性能评测中有关加速比的三个重要定律：适用于固定计算负载的 Amdahl 定律、适用于可扩放问题的的 Gustafson 定律、和受限于存储器的 Sun-Ni 定律。","text":"&emsp;&emsp; 并行计算的性能评测，大致分为三个层级：机器级、算法级、程序级。机器级的性能评测主要包括 CPU 和存储器的某些基本性能指标，并行通信开销，性价比等；算法级性能评测主要包括加速、效率、可扩放性等；程序级性能评测主要包括在基本测试程序、数学库测试程序和并行测试程序等。 —— 摘自 陈国良《并行计算 算法·结构·编程》 &emsp;&emsp; 本文主要集中讨论算法级性能评测中有关加速比的三个重要定律：适用于固定计算负载的 Amdahl 定律、适用于可扩放问题的的 Gustafson 定律、和受限于存储器的 Sun-Ni 定律。 为了方便描述，我们定义部分参数用于加速定律的公式化描述： W：问题规模，也叫做工作负载或计算负载。定义为给定问题的计算总量：$W = W_s + W_p$ $W_s$：应用程序中的串行分量 $W_p$：应用程序中并行分量 p：处理器数目 f：表示程序中的串行分量比例，$f = \\frac{W_s}{W}$ $T_s$：串行执行时间 $T_p$：并行执行时间 S：加速比，定义为对于给定对的程序，并行算法的执行速度想对于串行算法的执行速度加快了多少倍。 E：效率 Amdahl 定律&emsp;&emsp; 对于大多数科学计算，实时性是一个硬性要求，即计算任务必须在一定的计算时间内完成，但问题的计算总量是恒定的。因此，在计算负载恒定的情况下，我们可以通过增加处理器数量，将固定的工作负载分担到多个处理器上执行，从而加快执行速度。在这一前提下，Amdahl 于 1967 年推导出了固定负载下的加速比计算公式： S = \\frac{W_s + W_p}{W_s + \\frac{W_p}{p}}对上面的公式进行归一化简，得到： S = \\frac{f + (1-f)}{f+\\frac{1-f}{p}} = \\frac{p}{1+f(p-1)}随着处理器数目的增加，当 $p \\rightarrow \\infty$，该式的极限为： S = \\frac{1}{f}&emsp;&emsp; 这就是著名的 Amdahl 定律，它意味着随着处理器数目的无限增大，并行系统能达到的加速比上限为$\\frac{1}{f}$ ，这是一个悲观的结论。Amdahl 定律告诉我们两点内容： 在工作负载不变的前提下，随着处理器数量的增加，加速比增大，但增加的幅度很小 在工作负载不变的前提下，当处理器的数目增加到一定数目时，加速比与程序的串行分量成反比 &emsp;&emsp; 实际上，在串行算法被转化为并行算法后，我们还需要考虑并行算法带来的额外开销，比如并行通信开销，我们用$W_o$ 表示额外开销，则 Amdahl 定律应该表示为： S = \\frac{W_s + W_p}{W_s + \\frac{W_p}{p} + W_o} = \\frac{p}{1+f(p-1)+p\\frac{W_o}{W}}当 $p \\rightarrow \\infty$，该式的极限为： S = \\frac{1}{f + \\frac{W_o}{W}}由此可见，程序的串行分量和并行额外开销越大，对程序的加速效果越微弱。 Gustafson 定律&emsp;&emsp; 在很多大型计算中，对精度有着很高的要求，并且要求随着精度的提高，应用的计算时间固定不变。而提高精度的同时，计算总量也相应的增大了，因此必须相应的增加处理器的数量才能维持计算时间的恒定。我们再回顾一下 Amdahl 定律，这种在固定负载下盲目增加处理器数量的做法是毫无意义的，增加处理器的数目必须能够应对更大的问题规模，这样的系统才具有实用性。在这一前提下，Gustafson 在 1987 年提出了固定时间下放大问题规模的加速比计算公式： 假设增大问题规模后，计算总量为$W = W_s + pW_p$ S = \\frac{W_s + pW_p}{W_s + \\frac{pW_p}{p}} = \\frac{W_s + pW_p}{W_s+W_p} 对上式进行归一化简，可得： S = f + p (1-f) = p + f(1-p) = p - f(p-1)&emsp;&emsp; 在 Gustafson 定律中包含着一个隐性条件：随着处理器的数量增加，问题规模随之增加，增加的是应用程序的并行部分。同时，Gustafson 定律向我们传达的信息有三点： 当 $p$ 足够大时，$S$ 几乎与 $p$ 成线性关系，其斜率为$1-f$。即随着处理器数目的增加，加速随之成比例增加 这意味着 程序的串行比例 $f$ 不再是程序的瓶颈，这是个很乐观的结论。 同样，考虑到并行算法带来的额外开销$W_o$，Gustafson 定律应当表示为 S = \\frac{W_s + pW_p}{W_s + \\frac{pW_p}{p}+W_o} = \\frac{f+p(1-f)}{1 + \\frac{W_o}{W}}&emsp;&emsp; 由此可见，想要达到线性加速，必须使得p 足够大，而 $W_o$ 尽可能小。而 $W_o$ 是和 p 相关的，它可能随着 $p$ 增大、减小或不变，但想要使 $W_o$ 随着 $p$ 的增大而减小，即在增大处理器数目的同时减小额外开销，这往往是很困难的。 Sun-Ni 定律&emsp;&emsp; 由于 Amdahl 定律和 Gustafson 定律都存在某种限制，只适用于特定的场景。 Xian - He Sun 和 Lionel Ni 在 1983 年想要将二者一般化，于是提出了存储受限的加速定律。其基本思想是：只要存储空间允许，应尽量增加问题规模以产生更好的解，并使得执行时间只是略有增加。 &emsp;&emsp; 我们假定在单节点上使用了全部的存储容量 $M$ ，并在相应的 $W$ 的时间内求解该问题，此时工作负载为$W = fW +(1-f)W$ 。而在 $p$ 个结点的并行系统中，可用的存储容量扩展到了 $pM$，因此可以支撑更大的问题规模。我们用 $G(p)$ 表示存储容量增加到 $p$ 倍后工作负载的增加量，则扩大后的工作负载$W = fW + G(p)(1-f)W$，所以存储受限的加锁比计算公式： S = \\frac{fW+(1-f)G(p)W}{fW+\\frac{(1-f)G(p)W}{p}}对上式进行归一化简，可得： S = \\frac{f+(1-f)G(p)}{f+\\frac{(1-f)G(p)}{p}}Sun-Ni 定律蕴含的内容有两点： 随着处理器数目的增加，并行系统可以支撑更大的工作负载 随着处理器数目和工作负载的增加，执行时间只产生了少许增加。 同样，考虑到并行算法带来的额外开销，Gustafson 定律应当表示为 S = \\frac{W + (1-f)G(p)W}{fW + \\frac{(1-f)G(p)W}{p}+W_o} = \\frac{f+G(p)(1-f)}{f + (1-f)G(p) + \\frac{W_o}{W}}&emsp;&emsp;与此同时，Sun-Ni 定律是对 Amdahl 定律和 Gustafson 定律的一般化表示，因而可以进行特化，应对不同的集体场景； 当 $G(p) = 1$ 时，表示工作负载恒定，上面的公式变为了 $S = \\frac{1}{f+\\frac{1-f}{p}}$，对应 Amdahl 定律 当 $G(p) = p$ 时，上面的公式变为了 $ S = f + p(1-f)$，对应 Gustafson 定律 当 $G(p) &gt; p$ 时，上面的公式意味着计算负载比存储需求增加的快，此时 Sun-Ni 定律的加速比高于Amdahl 定律和 Gustafson 定律 有关加速的讨论&emsp;&emsp; 通过以上三条加速比定律我们可以看到，严格的线性加速是难以达到的，超线性加速就更不用说了。但在某些算法或者程序中，可能会出现超线性的加速现象：比如在某些并行搜索算法中，允许不同的处理器在不同的分支上同时搜索，一旦某个处理器迅速找到了目标，就向其它处理器发出停止搜索的信号，从而减少串行算法中那些无用的搜索分支，从而出现超线性的加速现象；又比如，在大多数并行机中，每个处理器都有少量高速缓存，当某问题在大量处理器上执行时，而其数据均放在高速缓存中时，相比于串行算法，I/O时间减少，总的计算时间随之减少，这种高速缓存造成的计算时间下降补偿了通信等造成的额外开销，就可能会出现超线性加速现象。 &emsp;&emsp; 其次，我们可以看到，无论是 Gustafson 定律还是 Sun-Ni 定律，谈到问题规模的增加时，增加的都是问题的并行分量，旨在降低串行分量对加速的影响。 &emsp;&emsp; 最后，有关加速的含义：科研工作者更乐意使用绝对加速的概念，即对于给定的问题，最佳串行算法所用的时间除以其并行算法所用的时间；而工程开发人员更偏向于使用相对加速的概念，即对于给定的问题，同一个算法在单处理器上运行的时间除以其在多处理器上运行的时间。很明显，相对加速的定义更为宽松和实用。","categories":[{"name":"并行计算","slug":"并行计算","permalink":"https://moonkie.xyz/categories/并行计算/"}],"tags":[{"name":"Amdahl 定律","slug":"Amdahl-定律","permalink":"https://moonkie.xyz/tags/Amdahl-定律/"},{"name":"Gustafson 定律","slug":"Gustafson-定律","permalink":"https://moonkie.xyz/tags/Gustafson-定律/"},{"name":"Sun-Ni 定律","slug":"Sun-Ni-定律","permalink":"https://moonkie.xyz/tags/Sun-Ni-定律/"}]},{"title":"搭建伪分布式 Hadoop 集群","slug":"搭建伪分布式Hadoop集群","date":"2018-03-24T15:48:04.000Z","updated":"2018-10-02T10:36:18.495Z","comments":true,"path":"2018/03/24/搭建伪分布式Hadoop集群/","link":"","permalink":"https://moonkie.xyz/2018/03/24/搭建伪分布式Hadoop集群/","excerpt":"&emsp;&emsp; 本次练习想要搭建一个3个结点的伪分布式Hadoop集群，并使用Markdown记录整个过程。","text":"&emsp;&emsp; 本次练习想要搭建一个3个结点的伪分布式Hadoop集群，并使用Markdown记录整个过程。 环境及对应软件版本 VMware® Workstation 12 Pro 12.5.7 build-5813279 CentOS Linux 7 Hadoop 2.8.1 openjdk 1.8.0_141 参考文档 Apache Hadoop 2.8.0官方文档 CentOS 7 下关于时间和日期以及时间同步的应用 Hadoop完全分布式集群搭建手记 Hadoop入门基础教程 Hadoop之完全分布式环境搭建 详细步骤配置CentOS添加用户，并赋予用户系统权限&emsp;1. 为Hadoop添加一个用户，用于进行各种配置。 执行命令 su -切换到root用户。 执行命令groupadd hadoop，添加一个名为hadoop的用户组。 执行命令useradd hadoop -g hadoop，添加一个名为hadoop的用户并加入hadoop用户组。 &emsp;2. 授予用户系统权限，以便执行随后的安装配置等一系列操作。 执行命令 su -切换到root用户。 执行命令chmod u+w /etc/sudoers 添加文件的写权限。 执行命令vim /etc/sudoers编辑文件: 找到 root ALL=(ALL) ALL 在下一行添加username ALL=(ALL) ALL，赋予用户系统权限。 保存并退出。 执行命令chmod u-w /etc/sudoers 撤销文件的写权限。 设置时钟同步&emsp;从CentOS 7开始，时间设置使用了一个新的命令 timedatectl。 执行命令 su - hadoop，切换回hadoop用户。 执行命令 timedatectl status, 查看当前时间。 执行命令 timedatectl set-timezone Asia/Shanghai，设置时区为上海。 执行命令timedatectl set-ntp yes，启用时间同步。 关闭防火墙 执行命令systemctl stop firewalld.service，关闭防火墙。 执行命令systemctl disable firewalld.service，禁止防火墙开机启动。 关闭SELINUX 执行命令sudo vim /etc/sysconfig/selinux，打开配置文件。 注释掉SELINUX=enforcing和SELINUXTYPE=targeted。 添加SELINUX=disabled。 保存并退出。 配置Java环境&emsp;关于jdk版本的选择需要考虑到Hadoop的兼容性，具体参考HadoopJavaVersions。不必特意使用 rpm卸载 Java，因为 rpm 可以在安装新版本时自动卸载旧版本的 Java，除非您准备永久删除 Java。 安装 执行命令 yum list java*，查看以Java关键字 开头的包。 执行命令sudo yum install java-1.8.0-openjdk*, 安装openjdk1.8(此处的jdk版本可以自行选择)。 一路输入yes, 等待安装结束。 配置&emsp;Java的环境变量配置有两个选择，具体的配置分布在两个不同的文件中：/etc/profile和~/.bash_profile。区别在于：/etc/profile是系统整体配置文件，其修改对系统下的所有用户有效，一般不建议修改；~/.bash_profile属于用户个人配置文件，用于用户个人配置，用户要修改自己的数据时，在此处修改。本次我们选择在/etc/profile中配置。 &emsp;如果不确定java环境安装到哪了，可以执行命令rpm -qa | grep java查看有哪些java相关的包, 然后执行命令rpm -ql java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64查看这个叫java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64的包的相关的文件安装到哪些目录了，从结果中可以确定java_path应该是/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64。 &emsp;一切准备就绪，就可以开始配置环境变量了： 执行命令sudo vim /etc/profile，打开配置文件。 在文件的末尾添加： 12export JAVA_HOME=java_pathexport PATH=\\$JAVA_HOME/bin:$PATH 保存并关闭文件，执行命令source /etc/profile 使变动生效。 配置SSH免密钥登录安装ssh&emsp; 通过安装并配置ssh， 可以使用Hadoop脚本管理远程Hadoop守护程序，省去反复输入密码的麻烦。 执行命令 yum install openssh-server -y，安装ssh对应的包。 配置ssh服务，也可跳过这步选择默认的配置。 OpenSSH的配置文件：/etc/ssh/sshd_config，可选的常用的配置如下： 执行命令systemctl reload sshd， 重启ssh 服务。 执行命令systemctl enable sshd，设置开机自启。 配置 作用 Port=22 设置SSH的端口号是22(默认端口号为22) Protocol 2 启用SSH版本2协议 ListenAddress 192.168.0.22 设置服务监听的地址 DenyUsers user1 user2 foo 拒绝访问的用户(用空格隔开) AllowUsers root osmond vivek 允许访问的用户(用空格隔开) PermitRootLogin no 禁止root用户登陆 PermitEmptyPasswords no 用户登陆需要密码认证 PasswordAuthentication yes 启用口令认证方式 &emsp;以上的配置需要在每台CentOS虚拟机上进行操作，我们可以在一台虚拟机上完成所有配置，然后再克隆出两份，所以我们就有了三台配置好的虚拟机。我们分别给三台虚拟机起名叫Master、Node1、Node2。其中Master作为namenode，Node1、Node2作为datanode。 &emsp;执行命令su - hadoop切换到hadoop用户，以下所有操作均需在hadoop用户下执行。 修改主机名及host文件&emsp;以下操作需要分别在Master、Node1、Node2三个结点上分别完整执行一次。首先我们以Master节点为例： 修改主机名 &emsp;修改主机名主要是为了方便辨识。执行命令hostnamectl set-hostname Master —static，即可将hostname设置为Master。 设置host文件 ​ &emsp;设置host文件可以使计算机之间通过计算机名进行访问。执行命令sudo vim /etc/hosts，在文件的末尾添加：123192.168.1.1(Master&apos;s IP) Master192.168.1.2(Node1&apos;s IP) Node1192.168.1.3(Node2&apos;s IP) Node2 ​ &emsp;保存并关闭文件。 随后，分别在Node1和Node2节点上重复上述操作。 配置SSH免密钥登录 &emsp;以 Master 为例，任何一台机器的~/.ssh/authorized_keys里保存了Master这台机器的公钥id_rsa.pub，那么这台机器就可以被Master用免密码方式ssh登录。所以，在下面的配置中，我们需要在每一个节点的~/.ssh/authorized_keys里添加另外两个节点的公钥id_rsa.pub。 在 Master、Node1、Node2 结点分别执行命令ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa，生成各自的密钥。 在 Master、Node1、Node2 结点分别执行命令cd ~/.ssh，进入到各自密钥所在目录。 在 Node1、Node2 节点分别执行命令，将各自节点的公钥发送到Master节点。 12Node1: scp id_rsa.pub Master:/home/hadoop/.ssh/id_rsa.pub.node1Node2: scp id_rsa.pub Master:/home/hadoop/.ssh/id_rsa.pub.node2 在 Master 结点执行以下命令，将3个节点的公钥分别追加到 Master 节点的~/.ssh/authorized_keys文件中。 123cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keyscat ~/.ssh/id_rsa.pub.node1 &gt;&gt; ~/.ssh/authorized_keyscat ~/.ssh/id_rsa.pub.node2 &gt;&gt; ~/.ssh/authorized_keys 在 Master 节点执行以下命令，将~/.ssh/authorized_keys文件复制到Node1、Node2两个节点上。 12scp authorized_keys Node1:/home/hadoop/.ssh/scp authorized_keys Node2:/home/hadoop/.ssh/ 在Master、Node1、Node2结点分别执行命令chmod 0600 ~/.ssh/authorized_keys，为该文件设置权限。 &emsp;到此为止，三个节点之中任意一个节点都可以通过ssh hostname免密码登录另外两个节点。 配置Hadoop环境&emsp;我们可以从Hadoop官网选择一个喜欢的Hadoop版本并下载，此处我们选择的Hadoop版本是hadoop-2.8.1.tar.gz。 Master节点环境配置Hadoop 安装我们将下载得到的Hadoop安装包放在/home/hadoop/目录下。 执行命令su - hadoop，切换到hadoop用户。 执行命令cd /home/hadoop，切换到hadoop安装包所在路径。 执行命令tar -xvf hadoop-2.8.1.tar.gz，将安装包在此处解压缩。 执行命令mv hadoop-2.8.1 hadoop，将解压后的安装包目录重命名为hadoop。 执行命令rm -rf /home/hadoop/hadoop-2.8.1.tar.gz，删除压缩包文件。 ​ Hadoop 配置 &emsp;研究了好久，我个人觉得Hadoop的配置属于可选性配置。它提供了很多可选的配置满足不同的需求，这就很头大。全部配上去似乎很搞笑，但随意配几个又怕遗漏什么东西。我试图找出那些必须的配置，但失败了。目前就只能参考网上的博客中的通用配置。关于每项配置的具体含义，请参考Apache Hadoop 2.8.0官方文档 配置Hadoop环境变量 &emsp;执行命令sudo vim /etc/profile，打开系统配置文件，在末尾添加以下内容：123# HADOOPexport HADOOP_HOME=/home/hadoop/hadoopexport PATH=$PATH:$HADOOP_HOME/bin &emsp;执行命令source /etc/profile，使命令在当前终端生效，完成环境变量的配置。 &emsp;在进行下一步操作前，我们先执行命令cd ~/hadoop/etc/hadoop，切换到Hadoop配置文件所在的目录。这里有我们接下来要配置的所有文件。 配置hadoop-env.sh &emsp;Hadoop环境是基于JVM虚拟机环境的，因此需要在hadoop-env.sh配置文件中指定Java环境。执行命令sudo vim hadoop-env.sh，打开该配置文件，找到1export JAVA_HOME=$&#123;JAVA_HOME&#125; &emsp;将其改为:1export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64 &emsp;保存并退出。 配置core-site.xml &emsp;core-site.xml 通常用于配置默认的文件系统和Hadoop数据临时目录。执行命令sudo vim core-site.xml，打开该配置文件。12345678910&lt;configuration&gt;&lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;file:/home/hadoop/hadoop/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;fs.defaultFS&lt;/name&gt;&lt;value&gt;hdfs://Master:9000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; &emsp;保存并退出。然后，我们需要在本地文件系统对应的位置创建该临时目录：1sudo mkdir /home/hadoop/hadoop/tmp 配置hdfs-site.xml &emsp; hdfs-site.xml通常用于指定HDFS的备份数，以及namenode节点和datanode节点的文件存储目录。执行命令sudo vim hdfs-site.xml，打开该配置文件1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.date.dir&lt;/name&gt; &lt;value&gt;home/hadoop/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; &emsp;保存并退出。 配置 mapred-site.xml &emsp;mapred-site.xml主要用于指定JobTracker的地址和端口。在配置文件的目录下，没有MapReduce的配置文件 mapred-site.xml，但存在一个模板文件 mapred-site.xml.template，我们可以复制该文件生成一个配置文件：1cp mapred-site.xml.template mapred-site.xml &emsp;执行命令mapred-site.xml，打开该配置文件。12345678910111213141516171819202122232425&lt;configuration&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobtracker.address&lt;/name&gt;&lt;value&gt;Master:9001&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.job.maps&lt;/name&gt;&lt;value&gt;20&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.job.reduces&lt;/name&gt;&lt;value&gt;4&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;&lt;value&gt;Master:10020&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;&lt;value&gt;Master:19888&lt;/value&gt;&gt;&lt;/property&gt;&lt;/configuration&gt; &emsp;保存并退出。 配置yarn-env.sh &emsp;YARN环境同样是基于JVM虚拟机环境的，因此需要在yarn-env.sh配置文件中指定JAVA环境。执行命令sudo vim yarn-env.sh，打开该配置文件，找到：1export JAVA_HOME=$&#123;JAVA_HOME&#125; &emsp;将其改为:1export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64 &emsp;保存并退出。 配置yarn-site.xml &emsp;yarn-site.xml为YARN框架的配置，主要是一些任务的启动位置。执行命令sudo vim yarn-site.xml，打开该配置文件。12345678910111213141516171819202122232425262728293031&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;&lt;value&gt;Master:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;&lt;value&gt;Master:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;&lt;value&gt;Master:8088&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;&lt;value&gt;Master:8031&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;&lt;value&gt;Master:8033&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; &emsp;保存并退出。 配置slaves文件 &emsp;该文件属于namenode节点独有，用于指定所有datanode所在节点。执行命令sudo vim slave，打开配置文件，内容如下：1localhost &emsp;删除localhost，添加 2 个datanode的主机名，修改后内容如下：12Node1Node2 &emsp;保存并退出。Master 节点的所有环境配置到此结束。 Slave节点环境配置复制Hadoop环境&emsp;在Node1和Node2节点进行环境配置时，本应重复3.1中的所有步骤。但为了方便起见，我们可以将Master结点配置好的Hadoop复制到Node1和Node2节点。 在Master 节点中，分别执行以下命令：12scp –r ~/hadoop hadoop@Node1:~/scp –r ~/hadoop hadoop@Node2:~/ &emsp;完成环境的复制。 删除slaves文件 &emsp;因为slaves文件是namenode节点所独有的，所以我们要删除Node1和Node2节点中的slaves文件。在Node1和Node2节点中分别执行下面这条命令：1rm -rf ~/hadoop/etc/hadoop/slaves &emsp;完成该文件的删除。 配置Hadoop环境变量&emsp;在Node1和Node2节点，分别执行命令sudo vim /etc/profile，打开系统配置文件，在末尾添加以下内容：123#HADOOPexport HADOOP_HOME=/home/hadoop/hadoopexport PATH=$PATH:$HADOOP_HOME/bin &emsp;执行命令source /etc/profile，使命令在当前终端生效，完成环境变量的配置。Node1 和Node2 节点的所有环境配置到此结束。 启动并运行Hadoop格式化HDFS文件系统&emsp;在第一次启动HDFS文件系统之前，我们需要对其进行格式化。格式化操作必须在在namenode节点上通过hadoop用户执行，而且只需要执行一次，下次启动时不再需要格式化操作，直接启动对应的服务即可。执行命令hadoop/bin/hdfs namenode -format，完成初始化操作。 启动Hadoop集群要启动Hadoop集群，我们需要启动HDFS和YARN集群。 执行命令hadoop/sbin/start-dfs.sh，启动HDFS。 执行命令hadoop/sbin/start-yarn.sh，启动YARN集群。 查看集群状态Hadoop集群启动并成功运行后，我们可以通过两种方式查看该Hadoop集群的运行状态。 通过命令行查看 执行命令jps，查看HDFS文件管理系统、MapReduce等服务是否启动成功。 执行命令hdfs dfsadmin -report，查看整个Hadoop集群的运行状态。该命令可以快速定位出哪些节点出了问题，HDFS的容量和其使用量，以及每个节点的硬盘使用情况。 通过web界面查看 页面 地址 NameNode http://Master:50070 ResourceManager http://Master:8088 关闭Hadoop集群要关闭Hadoop集群，我们同样需要关闭HDFS和YARN集群。 执行命令hadoop/sbin/stop-dfs.sh，关闭HDFS。 执行命令hadoop/sbin/stop-yarn.sh，关闭YARN集群。","categories":[{"name":"大数据","slug":"大数据","permalink":"https://moonkie.xyz/categories/大数据/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://moonkie.xyz/tags/Hadoop/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://moonkie.xyz/tags/环境搭建/"}]}]}
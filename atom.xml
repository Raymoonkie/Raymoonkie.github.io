<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>moonkie</title>
  
  <subtitle>Living like a beam of light</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://moonkie.xyz/"/>
  <updated>2018-10-02T09:14:53.382Z</updated>
  <id>https://moonkie.xyz/</id>
  
  <author>
    <name>moonkie</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>并行计算性能测评</title>
    <link href="https://moonkie.xyz/2018/04/08/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%84/"/>
    <id>https://moonkie.xyz/2018/04/08/并行计算性能测评/</id>
    <published>2018-04-08T12:23:09.000Z</published>
    <updated>2018-10-02T09:14:53.382Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp; 并行计算的性能评测，大致分为三个层级：机器级、算法级、程序级。机器级的性能评测主要包括 CPU 和存储器的某些基本性能指标，并行通信开销，性价比等；算法级性能评测主要包括加速、效率、可扩放性等；程序级性能评测主要包括在基本测试程序、数学库测试程序和并行测试程序等。</p><p align="right">—— 摘自 陈国良《并行计算 算法·结构·编程》</p><p>&emsp;&emsp; 本文主要集中讨论算法级性能评测中有关加速比的三个重要定律：适用于固定计算负载的 Amdahl 定律、适用于可扩放问题的的 Gustafson 定律、和受限于存储器的 Sun-Ni 定律。</p><a id="more"></a><p>为了方便描述，我们定义部分参数用于加速定律的公式化描述：</p><ul><li>W：问题规模，也叫做工作负载或计算负载。定义为给定问题的计算总量：$W = W_s + W_p$</li><li>$W_s$：应用程序中的串行分量</li><li>$W_p$：应用程序中并行分量</li><li>p：处理器数目</li><li>f：表示程序中的串行分量比例，$f = \frac{W_s}{W}$</li><li>$T_s$：串行执行时间</li><li>$T_p$：并行执行时间</li><li>S：加速比，定义为对于给定对的程序，并行算法的执行速度想对于串行算法的执行速度加快了多少倍。</li><li>E：效率</li></ul><h3 id="Amdahl-定律"><a href="#Amdahl-定律" class="headerlink" title="Amdahl 定律"></a>Amdahl 定律</h3><p>&emsp;&emsp; 对于大多数科学计算，实时性是一个硬性要求，即计算任务必须在一定的计算时间内完成，但问题的计算总量是恒定的。因此，在计算负载恒定的情况下，我们可以通过增加处理器数量，将固定的工作负载分担到多个处理器上执行，从而加快执行速度。在这一前提下，Amdahl 于 1967 年推导出了固定负载下的加速比计算公式：</p><script type="math/tex; mode=display">S = \frac{W_s + W_p}{W_s + \frac{W_p}{p}}</script><p>对上面的公式进行归一化简，得到：</p><script type="math/tex; mode=display">S = \frac{f + (1-f)}{f+\frac{1-f}{p}} = \frac{p}{1+f(p-1)}</script><p>随着处理器数目的增加，当 $p \rightarrow \infty$，该式的极限为：</p><script type="math/tex; mode=display">S = \frac{1}{f}</script><p>&emsp;&emsp; 这就是著名的 Amdahl 定律，它意味着随着处理器数目的无限增大，并行系统能达到的加速比上限为$\frac{1}{f}$ ，这是一个悲观的结论。Amdahl 定律告诉我们两点内容：</p><ol><li>在工作负载不变的前提下，随着处理器数量的增加，加速比增大，但增加的幅度很小</li><li>在工作负载不变的前提下，当处理器的数目增加到一定数目时，加速比与程序的串行分量成反比</li></ol><p>&emsp;&emsp; 实际上，在串行算法被转化为并行算法后，我们还需要考虑并行算法带来的额外开销，比如并行通信开销，我们用$W_o$ 表示额外开销，则 Amdahl 定律应该表示为：</p><script type="math/tex; mode=display">S = \frac{W_s + W_p}{W_s + \frac{W_p}{p} + W_o} = \frac{p}{1+f(p-1)+p\frac{W_o}{W}}</script><p>当 $p \rightarrow \infty$，该式的极限为：</p><script type="math/tex; mode=display">S = \frac{1}{f + \frac{W_o}{W}}</script><p>由此可见，程序的串行分量和并行额外开销越大，对程序的加速效果越微弱。</p><h3 id="Gustafson-定律"><a href="#Gustafson-定律" class="headerlink" title="Gustafson 定律"></a>Gustafson 定律</h3><p>&emsp;&emsp; 在很多大型计算中，对精度有着很高的要求，并且要求随着精度的提高，应用的计算时间固定不变。而提高精度的同时，计算总量也相应的增大了，因此必须相应的增加处理器的数量才能维持计算时间的恒定。我们再回顾一下 Amdahl 定律，这种在固定负载下盲目增加处理器数量的做法是毫无意义的，增加处理器的数目必须能够应对更大的问题规模，这样的系统才具有实用性。在这一前提下，Gustafson 在 1987 年提出了固定时间下放大问题规模的加速比计算公式：</p><p>假设增大问题规模后，计算总量为$W = W_s + pW_p$</p><script type="math/tex; mode=display">S = \frac{W_s + pW_p}{W_s + \frac{pW_p}{p}} = \frac{W_s + pW_p}{W_s+W_p}</script><p> 对上式进行归一化简，可得：</p><script type="math/tex; mode=display">S = f + p (1-f) = p + f(1-p) = p - f(p-1)</script><p>&emsp;&emsp; 在 Gustafson 定律中包含着一个隐性条件：随着处理器的数量增加，问题规模随之增加，增加的是应用程序的并行部分。同时，Gustafson 定律向我们传达的信息有三点：</p><ol><li><p>当 $p$ 足够大时，$S$ 几乎与 $p$ 成线性关系，其斜率为$1-f$。即随着处理器数目的增加，加速随之成比例增加</p></li><li><p>这意味着 程序的串行比例 $f$ 不再是程序的瓶颈，这是个很乐观的结论。</p></li></ol><p>同样，考虑到并行算法带来的额外开销$W_o$，Gustafson 定律应当表示为</p><script type="math/tex; mode=display">S = \frac{W_s + pW_p}{W_s + \frac{pW_p}{p}+W_o} = \frac{f+p(1-f)}{1 + \frac{W_o}{W}}</script><p>&emsp;&emsp; 由此可见，想要达到线性加速，必须使得p 足够大，而 $W_o$ 尽可能小。而 $W_o$ 是和 p 相关的，它可能随着 $p$ 增大、减小或不变，但想要使 $W_o$ 随着 $p$ 的增大而减小，即在增大处理器数目的同时减小额外开销，这往往是很困难的。</p><h3 id="Sun-Ni-定律"><a href="#Sun-Ni-定律" class="headerlink" title="Sun-Ni 定律"></a>Sun-Ni 定律</h3><p>&emsp;&emsp; 由于 Amdahl 定律和 Gustafson 定律都存在某种限制，只适用于特定的场景。  Xian - He Sun 和 Lionel Ni 在 1983 年想要将二者一般化，于是提出了存储受限的加速定律。其基本思想是：只要存储空间允许，应尽量增加问题规模以产生更好的解，并使得执行时间只是略有增加。</p><p>&emsp;&emsp; 我们假定在单节点上使用了全部的存储容量 $M$ ，并在相应的 $W$ 的时间内求解该问题，此时工作负载为$W = fW +(1-f)W$ 。而在 $p$ 个结点的并行系统中，可用的存储容量扩展到了 $pM$，因此可以支撑更大的问题规模。我们用 $G(p)$ 表示存储容量增加到 $p$ 倍后工作负载的增加量，则扩大后的工作负载$W = fW + G(p)(1-f)W$，所以存储受限的加锁比计算公式：</p><script type="math/tex; mode=display">S = \frac{fW+(1-f)G(p)W}{fW+\frac{(1-f)G(p)W}{p}}</script><p>对上式进行归一化简，可得：</p><script type="math/tex; mode=display">S = \frac{f+(1-f)G(p)}{f+\frac{(1-f)G(p)}{p}}</script><p>Sun-Ni 定律蕴含的内容有两点：</p><ol><li><p>随着处理器数目的增加，并行系统可以支撑更大的工作负载</p></li><li><p>随着处理器数目和工作负载的增加，执行时间只产生了少许增加。</p></li></ol><p>同样，考虑到并行算法带来的额外开销，Gustafson 定律应当表示为</p><script type="math/tex; mode=display">S = \frac{W + (1-f)G(p)W}{fW + \frac{(1-f)G(p)W}{p}+W_o} = \frac{f+G(p)(1-f)}{f + (1-f)G(p) + \frac{W_o}{W}}</script><p>&emsp;&emsp;与此同时，Sun-Ni 定律是对 Amdahl 定律和 Gustafson 定律的一般化表示，因而可以进行特化，应对不同的集体场景；</p><ul><li>当 $G(p) = 1$ 时，表示工作负载恒定，上面的公式变为了 $S = \frac{1}{f+\frac{1-f}{p}}$，对应 Amdahl 定律</li><li>当 $G(p) = p$ 时，上面的公式变为了 $ S = f + p(1-f)$，对应 Gustafson 定律</li><li>当 $G(p) &gt; p$ 时，上面的公式意味着计算负载比存储需求增加的快，此时 Sun-Ni 定律的加速比高于Amdahl 定律和 Gustafson 定律</li></ul><h3 id="有关加速的讨论"><a href="#有关加速的讨论" class="headerlink" title="有关加速的讨论"></a>有关加速的讨论</h3><p>&emsp;&emsp; 通过以上三条加速比定律我们可以看到，严格的线性加速是难以达到的，超线性加速就更不用说了。但在某些算法或者程序中，可能会出现超线性的加速现象：比如在某些并行搜索算法中，允许不同的处理器在不同的分支上同时搜索，一旦某个处理器迅速找到了目标，就向其它处理器发出停止搜索的信号，从而减少串行算法中那些无用的搜索分支，从而出现超线性的加速现象；又比如，在大多数并行机中，每个处理器都有少量高速缓存，当某问题在大量处理器上执行时，而其数据均放在高速缓存中时，相比于串行算法，I/O时间减少，总的计算时间随之减少，这种高速缓存造成的计算时间下降补偿了通信等造成的额外开销，就可能会出现超线性加速现象。</p><p>&emsp;&emsp; 其次，我们可以看到，无论是 Gustafson 定律还是 Sun-Ni 定律，谈到问题规模的增加时，增加的都是问题的并行分量，旨在降低串行分量对加速的影响。</p><p>&emsp;&emsp; 最后，有关加速的含义：科研工作者更乐意使用<strong>绝对加速</strong>的概念，即对于给定的问题，最佳串行算法所用的时间除以其并行算法所用的时间；而工程开发人员更偏向于使用<strong>相对加速</strong>的概念，即对于给定的问题，同一个算法在单处理器上运行的时间除以其在多处理器上运行的时间。很明显，<strong>相对加速</strong>的定义更为宽松和实用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp; 并行计算的性能评测，大致分为三个层级：机器级、算法级、程序级。机器级的性能评测主要包括 CPU 和存储器的某些基本性能指标，并行通信开销，性价比等；算法级性能评测主要包括加速、效率、可扩放性等；程序级性能评测主要包括在基本测试程序、数学库测试程序和并行测试程序等。&lt;/p&gt;
&lt;p align=&quot;right&quot;&gt;—— 摘自 陈国良《并行计算 算法·结构·编程》&lt;/p&gt;

&lt;p&gt;&amp;emsp;&amp;emsp; 本文主要集中讨论算法级性能评测中有关加速比的三个重要定律：适用于固定计算负载的 Amdahl 定律、适用于可扩放问题的的 Gustafson 定律、和受限于存储器的 Sun-Ni 定律。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://moonkie.xyz/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="并行计算" scheme="https://moonkie.xyz/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="Amdahl 定律" scheme="https://moonkie.xyz/tags/Amdahl-%E5%AE%9A%E5%BE%8B/"/>
    
      <category term="Gustafson 定律" scheme="https://moonkie.xyz/tags/Gustafson-%E5%AE%9A%E5%BE%8B/"/>
    
      <category term="Sun-Ni 定律" scheme="https://moonkie.xyz/tags/Sun-Ni-%E5%AE%9A%E5%BE%8B/"/>
    
      <category term="加速比" scheme="https://moonkie.xyz/tags/%E5%8A%A0%E9%80%9F%E6%AF%94/"/>
    
  </entry>
  
  <entry>
    <title>搭建伪分布式 Hadoop 集群</title>
    <link href="https://moonkie.xyz/2018/03/24/%E6%90%AD%E5%BB%BA%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8FHadoop%E9%9B%86%E7%BE%A4/"/>
    <id>https://moonkie.xyz/2018/03/24/搭建伪分布式Hadoop集群/</id>
    <published>2018-03-24T15:48:04.000Z</published>
    <updated>2018-04-09T03:21:20.072Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp; 本次练习想要搭建一个3个结点的伪分布式Hadoop集群，并使用Markdown记录整个过程。</p><a id="more"></a><h2 id="环境及对应软件版本"><a href="#环境及对应软件版本" class="headerlink" title="环境及对应软件版本"></a>环境及对应软件版本</h2><ul><li><strong>VMware® Workstation 12 Pro  12.5.7 build-5813279</strong></li><li><strong>CentOS Linux 7</strong></li><li><strong>Hadoop 2.8.1</strong></li><li><strong>openjdk 1.8.0_141</strong></li></ul><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><strong><a href="https://hadoop.apache.org/docs/r2.8.0/hadoop-project-dist/hadoop-common/ClusterSetup.html" target="_blank" rel="noopener">Apache Hadoop 2.8.0官方文档</a></strong></li><li><strong><a href="http://www.jianshu.com/p/fb32239ccf2b" target="_blank" rel="noopener">CentOS 7 下关于时间和日期以及时间同步的应用</a></strong></li><li><strong><a href="https://www.zybuluo.com/Emptyset/note/220230" target="_blank" rel="noopener">Hadoop完全分布式集群搭建手记</a></strong></li><li><strong><a href="http://www.linuxidc.com/Linux/2015-03/114669p4.htm" target="_blank" rel="noopener">Hadoop入门基础教程  Hadoop之完全分布式环境搭建</a></strong></li></ul><h2 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a>详细步骤</h2><h3 id="配置CentOS"><a href="#配置CentOS" class="headerlink" title="配置CentOS"></a>配置CentOS</h3><h4 id="添加用户，并赋予用户系统权限"><a href="#添加用户，并赋予用户系统权限" class="headerlink" title="添加用户，并赋予用户系统权限"></a>添加用户，并赋予用户系统权限</h4><p>&emsp;1. 为Hadoop添加一个用户，用于进行各种配置。</p><ul><li>执行命令 <strong><code>su  -</code></strong>切换到<strong>root</strong>用户。</li><li>执行命令<strong><code>groupadd hadoop</code></strong>，添加一个名为<strong>hadoop</strong>的用户组。</li><li>执行命令<strong><code>useradd hadoop -g hadoop</code></strong>，添加一个名为<strong>hadoop</strong>的用户并加入<strong>hadoop</strong>用户组。</li></ul><p>&emsp;2. 授予用户系统权限，以便执行随后的安装配置等一系列操作。</p><ul><li>执行命令 <strong><code>su  -</code></strong>切换到<strong>root</strong>用户。</li><li>执行命令<strong><code>chmod u+w /etc/sudoers</code></strong> 添加文件的写权限。</li><li>执行命令<strong><code>vim /etc/sudoers</code></strong>编辑文件: </li><li>找到 <strong><code>root  ALL=(ALL)  ALL</code></strong></li><li>在下一行添加<strong><code>username ALL=(ALL) ALL</code></strong>，赋予用户系统权限。</li><li>保存并退出。</li><li>执行命令<strong><code>chmod u-w /etc/sudoers</code></strong> 撤销文件的写权限。</li></ul><h4 id="设置时钟同步"><a href="#设置时钟同步" class="headerlink" title="设置时钟同步"></a>设置时钟同步</h4><p>&emsp;从CentOS 7开始，时间设置使用了一个新的命令 <strong>timedatectl。</strong></p><ul><li>执行命令 <strong><code>su - hadoop</code></strong>，切换回<strong>hadoop</strong>用户。</li><li>执行命令 <strong><code>timedatectl status</code></strong>, 查看当前时间。</li><li>执行命令 <strong><code>timedatectl set-timezone Asia/Shanghai</code></strong>，设置时区为上海。</li><li>执行命令<strong><code>timedatectl set-ntp yes</code></strong>，启用时间同步。</li></ul><h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h4><ul><li>执行命令<strong><code>systemctl stop firewalld.service</code></strong>，关闭防火墙。</li><li>执行命令<strong><code>systemctl disable firewalld.service</code></strong>，禁止防火墙开机启动。</li></ul><h4 id="关闭SELINUX"><a href="#关闭SELINUX" class="headerlink" title="关闭SELINUX"></a>关闭SELINUX</h4><ul><li>执行命令<strong><code>sudo vim /etc/sysconfig/selinux</code></strong>，打开配置文件。</li><li>注释掉<strong><code>SELINUX=enforcing</code></strong>和<strong><code>SELINUXTYPE=targeted</code></strong>。</li><li>添加<strong><code>SELINUX=disabled</code></strong>。</li><li>保存并退出。</li></ul><h3 id="配置Java环境"><a href="#配置Java环境" class="headerlink" title="配置Java环境"></a>配置Java环境</h3><p>&emsp;关于jdk版本的选择需要考虑到Hadoop的兼容性，具体参考<a href="https://wiki.apache.org/hadoop/HadoopJavaVersions" target="_blank" rel="noopener">HadoopJavaVersions</a>。不必特意使用 rpm卸载 Java，因为 rpm 可以在安装新版本时自动卸载旧版本的 Java，除非您准备永久删除 Java。</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><ul><li>执行命令 <strong><code>yum list java*</code></strong>，查看以<strong>Java</strong>关键字 开头的包。</li><li>执行命令<strong><code>sudo yum install java-1.8.0-openjdk*</code></strong>, 安装<strong>openjdk1.8</strong>(此处的jdk版本可以自行选择)。</li><li>一路输入<strong><code>yes</code></strong>, 等待安装结束。</li></ul><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>&emsp;Java的环境变量配置有两个选择，具体的配置分布在两个不同的文件中：<strong><code>/etc/profile</code></strong>和<strong><code>~/.bash_profile</code></strong>。区别在于：<strong><code>/etc/profile</code></strong>是系统整体配置文件，其修改对系统下的所有用户有效，一般不建议修改；<strong><code>~/.bash_profile</code></strong>属于用户个人配置文件，用于用户个人配置，用户要修改自己的数据时，在此处修改。本次我们选择在<strong><code>/etc/profile</code></strong>中配置。</p><p>&emsp;如果不确定<strong>java</strong>环境安装到哪了，可以执行命令<strong><code>rpm -qa | grep java</code></strong>查看有哪些<strong>java</strong>相关的包, 然后执行命令<strong><code>rpm -ql    java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64</code></strong>查看这个叫<strong><code>java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64</code></strong>的包的相关的文件安装到哪些目录了，从结果中可以确定<strong>java_path</strong>应该是<strong><code>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64</code></strong>。</p><p>&emsp;一切准备就绪，就可以开始配置环境变量了：</p><ul><li>执行命令<strong><code>sudo vim /etc/profile</code></strong>，打开配置文件。</li><li><p>在文件的末尾添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=java_path</span><br><span class="line">export PATH=\$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>保存并关闭文件，执行命令<strong><code>source  /etc/profile</code></strong> 使变动生效。</p></li></ul><h3 id="配置SSH免密钥登录"><a href="#配置SSH免密钥登录" class="headerlink" title="配置SSH免密钥登录"></a>配置SSH免密钥登录</h3><h4 id="安装ssh"><a href="#安装ssh" class="headerlink" title="安装ssh"></a>安装ssh</h4><p>&emsp; 通过安装并配置<strong>ssh</strong>， 可以使用Hadoop脚本管理远程Hadoop守护程序，省去反复输入密码的麻烦。</p><ul><li>执行命令 <strong><code>yum install openssh-server -y</code></strong>，安装<strong>ssh</strong>对应的包。</li><li>配置<strong>ssh</strong>服务，也可跳过这步选择默认的配置。 <strong>OpenSSH</strong>的配置文件：<strong><code>/etc/ssh/sshd_config</code></strong>，可选的常用的配置如下：</li><li>执行命令<strong><code>systemctl reload sshd</code></strong>， 重启<strong>ssh</strong> 服务。</li><li>执行命令<strong><code>systemctl enable sshd</code></strong>，设置开机自启。</li></ul><div class="table-container"><table><thead><tr><th>配置</th><th>作用</th></tr></thead><tbody><tr><td>Port=22</td><td>设置SSH的端口号是22(默认端口号为22)</td></tr><tr><td>Protocol 2</td><td>启用SSH版本2协议</td></tr><tr><td>ListenAddress 192.168.0.22</td><td>设置服务监听的地址</td></tr><tr><td>DenyUsers   user1 user2 foo</td><td>拒绝访问的用户(用空格隔开)</td></tr><tr><td>AllowUsers  root osmond vivek</td><td>允许访问的用户(用空格隔开)</td></tr><tr><td>PermitRootLogin  no</td><td>禁止root用户登陆</td></tr><tr><td>PermitEmptyPasswords no</td><td>用户登陆需要密码认证</td></tr><tr><td>PasswordAuthentication  yes</td><td>启用口令认证方式</td></tr></tbody></table></div><p>&emsp;以上的配置需要在每台CentOS虚拟机上进行操作，我们可以在一台虚拟机上完成所有配置，然后再克隆出两份，所以我们就有了三台配置好的虚拟机。我们分别给三台虚拟机起名叫Master、Node1、Node2。其中Master作为namenode，Node1、Node2作为datanode。</p><p>&emsp;执行命令<strong><code>su - hadoop</code></strong>切换到hadoop用户，以下所有操作均需在hadoop用户下执行。</p><h4 id="修改主机名及host文件"><a href="#修改主机名及host文件" class="headerlink" title="修改主机名及host文件"></a>修改主机名及host文件</h4><p>&emsp;以下操作需要分别在Master、Node1、Node2三个结点上分别完整执行一次。首先我们以Master节点为例：</p><ol><li><p>修改主机名</p><p>&emsp;修改主机名主要是为了方便辨识。执行命令<strong>hostnamectl set-hostname Master   —static</strong>，即可将<strong>hostname</strong>设置为<strong>Master</strong>。</p></li><li><p>设置host文件</p></li></ol><p>​      &emsp;设置<strong>host</strong>文件可以使计算机之间通过计算机名进行访问。执行命令<strong><code>sudo vim /etc/hosts</code></strong>，在文件的末尾添加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.1(Master&apos;s IP)    Master</span><br><span class="line">192.168.1.2(Node1&apos;s IP)     Node1</span><br><span class="line">192.168.1.3(Node2&apos;s IP)     Node2</span><br></pre></td></tr></table></figure></p><p>​    &emsp;保存并关闭文件。 随后，分别在Node1和Node2节点上重复上述操作。</p><h4 id="配置SSH免密钥登录-1"><a href="#配置SSH免密钥登录-1" class="headerlink" title="配置SSH免密钥登录"></a>配置SSH免密钥登录</h4><p> &emsp;以 <strong>Master</strong> 为例，任何一台机器的<strong><code>~/.ssh/authorized_keys</code></strong>里保存了<strong>Master</strong>这台机器的公钥<strong><code>id_rsa.pub</code></strong>，那么这台机器就可以被<strong>Master</strong>用免密码方式<strong>ssh</strong>登录。所以，在下面的配置中，我们需要在每一个节点的<strong><code>~/.ssh/authorized_keys</code></strong>里添加另外两个节点的公钥<strong><code>id_rsa.pub</code></strong>。</p><ul><li>在 <strong>Master、Node1、Node2</strong> 结点分别执行命令<strong><code>ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa</code></strong>，生成各自的密钥。</li><li>在 <strong>Master、Node1、Node2</strong> 结点分别执行命令<strong><code>cd ~/.ssh</code></strong>，进入到各自密钥所在目录。</li><li><p>在 <strong>Node1、Node2</strong> 节点分别执行命令，将各自节点的公钥发送到<strong>Master</strong>节点。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Node1:    scp id_rsa.pub Master:/home/hadoop/.ssh/id_rsa.pub.node1</span><br><span class="line">Node2:    scp id_rsa.pub Master:/home/hadoop/.ssh/id_rsa.pub.node2</span><br></pre></td></tr></table></figure></li><li><p>在 <strong>Master</strong> 结点执行以下命令，将3个节点的公钥分别追加到 <strong>Master</strong> 节点的<strong><code>~/.ssh/authorized_keys</code></strong>文件中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">cat ~/.ssh/id_rsa.pub.node1 &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">cat ~/.ssh/id_rsa.pub.node2 &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></li><li><p>在 <strong><em>Master</em></strong> 节点执行以下命令，将<strong><code>~/.ssh/authorized_keys</code></strong>文件复制到<strong>Node1、Node2</strong>两个节点上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp authorized_keys  Node1:/home/hadoop/.ssh/</span><br><span class="line">scp authorized_keys  Node2:/home/hadoop/.ssh/</span><br></pre></td></tr></table></figure></li><li><p>在<strong>Master、Node1、Node2</strong>结点分别执行命令<strong><code>chmod 0600 ~/.ssh/authorized_keys</code></strong>，为该文件设置权限。</p></li></ul><p>&emsp;到此为止，三个节点之中任意一个节点都可以通过<code>ssh hostname</code>免密码登录另外两个节点。</p><h3 id="配置Hadoop环境"><a href="#配置Hadoop环境" class="headerlink" title="配置Hadoop环境"></a>配置Hadoop环境</h3><p>&emsp;我们可以从<a href="http://hadoop.apache.org/releases.html" target="_blank" rel="noopener">Hadoop官网</a>选择一个喜欢的Hadoop版本并下载，此处我们选择的Hadoop版本是<strong><code>hadoop-2.8.1.tar.gz</code></strong>。</p><h4 id="Master节点环境配置"><a href="#Master节点环境配置" class="headerlink" title="Master节点环境配置"></a>Master节点环境配置</h4><h5 id="Hadoop-安装"><a href="#Hadoop-安装" class="headerlink" title="Hadoop 安装"></a>Hadoop 安装</h5><p>我们将下载得到的Hadoop安装包放在<strong><code>/home/hadoop/</code></strong>目录下。</p><ul><li><p>执行命令<strong><code>su - hadoop</code></strong>，切换到<strong>hadoop</strong>用户。</p></li><li><p>执行命令<strong><code>cd /home/hadoop</code></strong>，切换到<strong>hadoop</strong>安装包所在路径。</p></li><li><p>执行命令<strong><code>tar -xvf hadoop-2.8.1.tar.gz</code></strong>，将安装包在此处解压缩。</p></li><li><p>执行命令<strong><code>mv hadoop-2.8.1 hadoop</code></strong>，将解压后的安装包目录重命名为<strong>hadoop</strong>。</p></li><li><p>执行命令<strong><code>rm -rf  /home/hadoop/hadoop-2.8.1.tar.gz</code></strong>，删除压缩包文件。</p><p>​</p><h5 id="Hadoop-配置"><a href="#Hadoop-配置" class="headerlink" title="Hadoop 配置"></a>Hadoop 配置</h5></li></ul><p>&emsp;研究了好久，我个人觉得Hadoop的配置属于可选性配置。它提供了很多可选的配置满足不同的需求，这就很头大。全部配上去似乎很搞笑，但随意配几个又怕遗漏什么东西。我试图找出那些必须的配置，但失败了。目前就只能参考网上的博客中的通用配置。关于每项配置的具体含义，请参考<a href="https://hadoop.apache.org/docs/r2.8.0/hadoop-project-dist/hadoop-common/ClusterSetup.html" target="_blank" rel="noopener">Apache Hadoop 2.8.0官方文档</a></p><ol><li>配置Hadoop环境变量</li></ol><p>&emsp;执行命令<strong><code>sudo vim /etc/profile</code></strong>，打开系统配置文件，在末尾添加以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># HADOOP</span><br><span class="line">export HADOOP_HOME=/home/hadoop/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure></p><p>&emsp;执行命令<strong><code>source /etc/profile</code></strong>，使命令在当前终端生效，完成环境变量的配置。</p><p>&emsp;在进行下一步操作前，我们先执行命令<strong><code>cd ~/hadoop/etc/hadoop</code></strong>，切换到<strong>Hadoop</strong>配置文件所在的目录。这里有我们接下来要配置的所有文件。</p><ol><li>配置<strong>hadoop-env.sh</strong></li></ol><p>&emsp;<strong>Hadoop</strong>环境是基于<strong>JVM</strong>虚拟机环境的，因此需要在<strong><code>hadoop-env.sh</code></strong>配置文件中指定Java环境。<br>执行命令<strong><code>sudo vim hadoop-env.sh</code></strong>，打开该配置文件，找到<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=$&#123;JAVA_HOME&#125;</span><br></pre></td></tr></table></figure></p><p>&emsp;将其改为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64</span><br></pre></td></tr></table></figure></p><p>&emsp;保存并退出。</p><ol><li>配置core-site.xml</li></ol><p>&emsp;<strong><code>core-site.xml</code></strong> 通常用于配置默认的文件系统和<strong>Hadoop</strong>数据临时目录。执行命令<strong><code>sudo vim core-site.xml</code></strong>，打开该配置文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;file:/home/hadoop/hadoop/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hdfs://Master:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><p>&emsp;保存并退出。然后，我们需要在本地文件系统对应的位置创建该临时目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /home/hadoop/hadoop/tmp</span><br></pre></td></tr></table></figure></p><ol><li>配置hdfs-site.xml</li></ol><p>&emsp; <strong><code>hdfs-site.xml</code></strong>通常用于指定<strong>HDFS</strong>的备份数，以及<strong>namenode</strong>节点和<strong>datanode</strong>节点的文件存储目录。<br>执行命令<strong><code>sudo vim hdfs-site.xml</code></strong>，打开该配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;/home/hadoop/hadoop/hdfs/name&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.datanode.date.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;home/hadoop/hadoop/hdfs/data&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><p>&emsp;保存并退出。</p><ol><li>配置 mapred-site.xml</li></ol><p>&emsp;<strong><code>mapred-site.xml</code></strong>主要用于指定<strong>JobTracker</strong>的地址和端口。在配置文件的目录下，没有<strong>MapReduce</strong>的配置文件 <strong><code>mapred-site.xml</code></strong>，但存在一个模板文件 <strong><code>mapred-site.xml.template</code></strong>，我们可以复制该文件生成一个配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure></p><p>&emsp;执行命令<strong><code>mapred-site.xml</code></strong>，打开该配置文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobtracker.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:9001&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.job.maps&lt;/name&gt;</span><br><span class="line">&lt;value&gt;20&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.job.reduces&lt;/name&gt;</span><br><span class="line">&lt;value&gt;4&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:10020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:19888&lt;/value&gt;&gt;&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><p>&emsp;保存并退出。</p><ol><li>配置yarn-env.sh</li></ol><p>&emsp;<strong>YARN</strong>环境同样是基于<strong>JVM</strong>虚拟机环境的，因此需要在<strong>yarn-env.sh</strong>配置文件中指定<strong>JAVA</strong>环境。<br>执行命令<strong><code>sudo vim yarn-env.sh</code></strong>，打开该配置文件，找到：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=$&#123;JAVA_HOME&#125;</span><br></pre></td></tr></table></figure></p><p>&emsp;将其改为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64</span><br></pre></td></tr></table></figure></p><p>&emsp;保存并退出。</p><ol><li>配置yarn-site.xml</li></ol><p>&emsp;<strong><code>yarn-site.xml</code></strong>为<strong>YARN</strong>框架的配置，主要是一些任务的启动位置。执行命令<strong><code>sudo vim yarn-site.xml</code></strong>，打开该配置文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:8032&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:8030&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:8088&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:8031&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;Master:8033&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><p>&emsp;保存并退出。</p><ol><li>配置slaves文件</li></ol><p>&emsp;该文件属于<strong>namenode</strong>节点独有，用于指定所有<strong>datanode</strong>所在节点。<br>执行命令<strong><code>sudo vim slave</code></strong>，打开配置文件，内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">localhost</span><br></pre></td></tr></table></figure></p><p>&emsp;删除<strong>localhost</strong>，添加 <strong>2</strong> 个<strong>datanode</strong>的主机名，修改后内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Node1</span><br><span class="line">Node2</span><br></pre></td></tr></table></figure></p><p>&emsp;保存并退出。<strong>Master</strong> 节点的所有环境配置到此结束。</p><h4 id="Slave节点环境配置"><a href="#Slave节点环境配置" class="headerlink" title="Slave节点环境配置"></a>Slave节点环境配置</h4><h5 id="复制Hadoop环境"><a href="#复制Hadoop环境" class="headerlink" title="复制Hadoop环境"></a>复制Hadoop环境</h5><p>&emsp;在<strong>Node1</strong>和<strong>Node2</strong>节点进行环境配置时，本应重复<strong>3.1</strong>中的所有步骤。但为了方便起见，我们可以将<strong>Master</strong>结点配置好的<strong>Hadoop</strong>复制到<strong>Node1</strong>和<strong>Node2</strong>节点。 在<strong>Master</strong> 节点中，分别执行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp –r ~/hadoop hadoop@Node1:~/</span><br><span class="line">scp –r ~/hadoop hadoop@Node2:~/</span><br></pre></td></tr></table></figure></p><p> &emsp;完成环境的复制。</p><h5 id="删除slaves文件"><a href="#删除slaves文件" class="headerlink" title="删除slaves文件"></a>删除slaves文件</h5><p> &emsp;因为<strong>slaves</strong>文件是<strong>namenode</strong>节点所独有的，所以我们要删除<strong>Node1</strong>和<strong>Node2</strong>节点中的<strong>slaves</strong>文件。<br>在<strong>Node1</strong>和<strong>Node2</strong>节点中分别执行下面这条命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf  ~/hadoop/etc/hadoop/slaves</span><br></pre></td></tr></table></figure></p><p>&emsp;完成该文件的删除。</p><h5 id="配置Hadoop环境变量"><a href="#配置Hadoop环境变量" class="headerlink" title="配置Hadoop环境变量"></a>配置Hadoop环境变量</h5><p>&emsp;在<strong>Node1</strong>和<strong>Node2</strong>节点，分别执行命令<strong><code>sudo vim /etc/profile</code></strong>，打开系统配置文件，在末尾添加以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#HADOOP</span><br><span class="line">export HADOOP_HOME=/home/hadoop/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure></p><p>&emsp;执行命令<strong><code>source /etc/profile</code></strong>，使命令在当前终端生效，完成环境变量的配置。<strong>Node1</strong> 和<strong>Node2</strong> 节点的所有环境配置到此结束。</p><h3 id="启动并运行Hadoop"><a href="#启动并运行Hadoop" class="headerlink" title="启动并运行Hadoop"></a>启动并运行Hadoop</h3><h4 id="格式化HDFS文件系统"><a href="#格式化HDFS文件系统" class="headerlink" title="格式化HDFS文件系统"></a>格式化HDFS文件系统</h4><p>&emsp;在第一次启动<strong>HDFS</strong>文件系统之前，我们需要对其进行格式化。格式化操作必须在在<strong>namenode</strong>节点上通过<strong>hadoop</strong>用户执行，而且只需要执行一次，下次启动时不再需要格式化操作，直接启动对应的服务即可。<br>执行命令<strong><code>hadoop/bin/hdfs namenode -format</code></strong>，完成初始化操作。</p><h4 id="启动Hadoop集群"><a href="#启动Hadoop集群" class="headerlink" title="启动Hadoop集群"></a>启动Hadoop集群</h4><p>要启动<strong>Hadoop</strong>集群，我们需要启动<strong>HDFS</strong>和<strong>YARN</strong>集群。</p><ul><li>执行命令<strong><code>hadoop/sbin/start-dfs.sh</code></strong>，启动<strong>HDFS</strong>。</li><li>执行命令<strong><code>hadoop/sbin/start-yarn.sh</code></strong>，启动<strong>YARN</strong>集群。</li></ul><h4 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h4><p><strong>Hadoop</strong>集群启动并成功运行后，我们可以通过两种方式查看该<strong>Hadoop</strong>集群的运行状态。</p><ol><li>通过命令行查看</li></ol><ul><li>执行命令<code>jps</code>，查看HDFS文件管理系统、<strong>MapReduce</strong>等服务是否启动成功。</li><li>执行命令<strong><code>hdfs dfsadmin -report</code></strong>，查看整个<strong>Hadoop</strong>集群的运行状态。该命令可以快速定位出哪些节点出了问题，<strong>HDFS</strong>的容量和其使用量，以及每个节点的硬盘使用情况。</li></ul><ol><li>通过<strong>web</strong>界面查看</li></ol><div class="table-container"><table><thead><tr><th>页面</th><th>地址</th></tr></thead><tbody><tr><td>NameNode</td><td><a href="http://Master:50070" target="_blank" rel="noopener">http://Master:50070</a></td></tr><tr><td>ResourceManager</td><td><a href="http://Master:8088" target="_blank" rel="noopener">http://Master:8088</a></td></tr></tbody></table></div><h4 id="关闭Hadoop集群"><a href="#关闭Hadoop集群" class="headerlink" title="关闭Hadoop集群"></a>关闭Hadoop集群</h4><p>要关闭<strong>Hadoop</strong>集群，我们同样需要关闭<strong>HDFS</strong>和<strong>YARN</strong>集群。</p><ul><li>执行命令<strong><code>hadoop/sbin/stop-dfs.sh</code></strong>，关闭<strong>HDFS</strong>。</li><li>执行命令<strong><code>hadoop/sbin/stop-yarn.sh</code></strong>，关闭<strong>YARN</strong>集群。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp; 本次练习想要搭建一个3个结点的伪分布式Hadoop集群，并使用Markdown记录整个过程。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://moonkie.xyz/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hadoop" scheme="https://moonkie.xyz/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://moonkie.xyz/tags/Hadoop/"/>
    
      <category term="环境搭建" scheme="https://moonkie.xyz/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
</feed>
